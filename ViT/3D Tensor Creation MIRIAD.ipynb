{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e3e5815",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import time\n",
    "import pandas as pd\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import random\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "from scipy.ndimage import zoom\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "\n",
    "import gc\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "530221d4-fedb-4ffe-b925-1c4b0022cdb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"/home/admin1/Arindam/Alzheimer/PreprocessedData/miriad\"\n",
    "config = {\n",
    "    'img_size': 192,\n",
    "    'depth' : 192\n",
    "}\n",
    "\n",
    "random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "37b55e37-543f-43fa-824c-cc4f3084a587",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataPaths():\n",
    "    def __init__(self, data_path=DATA_PATH):\n",
    "        self.data_path = data_path\n",
    "\n",
    "    def mri_path_loading(self):\n",
    "        paths = []\n",
    "        for (root,dirs,files) in os.walk(self.data_path, topdown=True):\n",
    "            if len(files):\n",
    "                for file_path in files:\n",
    "                    if file_path.endswith('mni_norm.nii.gz'):\n",
    "                        paths.append(os.path.join(root, file_path))\n",
    "        \n",
    "        random.shuffle(paths)\n",
    "        return paths\n",
    "\n",
    "    def train_val_test_division(self, train_split=0.7, val_split=0.15, stratify=True):\n",
    "        test_split = 1 - (train_split + val_split)\n",
    "        image_paths = self.mri_path_loading()\n",
    "        AD_image_paths, HC_image_paths = [], []\n",
    "        for im_path in image_paths:\n",
    "            if \"_AD_\" in im_path:\n",
    "                AD_image_paths.append(im_path)\n",
    "            elif \"_HC_\" in im_path:\n",
    "                HC_image_paths.append(im_path)\n",
    "\n",
    "        assert len(AD_image_paths) + len(HC_image_paths) == len(image_paths)\n",
    "\n",
    "        no_of_images = {\n",
    "            \"train_ad\" : int(train_split*len(AD_image_paths)),\n",
    "            \"val_ad\" : int(val_split*len(AD_image_paths)),\n",
    "            \"test_ad\" : len(AD_image_paths) - int(train_split*len(AD_image_paths)) - int(val_split*len(AD_image_paths)),\n",
    "            \"train_hc\" : int(train_split*len(HC_image_paths)),\n",
    "            \"val_hc\" : int(val_split*len(HC_image_paths)),\n",
    "            \"test_hc\" : len(HC_image_paths) - int(train_split*len(HC_image_paths)) - int(val_split*len(HC_image_paths))\n",
    "        }\n",
    "        print(no_of_images)\n",
    "        len_train = no_of_images['train_ad'] + no_of_images['train_hc']\n",
    "        len_val = no_of_images['val_ad'] + no_of_images['val_hc']\n",
    "        len_test = no_of_images['test_ad'] + no_of_images['test_hc']\n",
    "        print(\"Total number of train, validation and test images are {}, {} and {} respectively.\".format(len_train, len_val, len_test))\n",
    "        \n",
    "        save_path = os.path.join(os.getcwd(), 'data/MIRIAD')\n",
    "        if os.path.exists(save_path)==False:\n",
    "            os.mkdir(save_path)\n",
    "\n",
    "        trin_img_df = pd.DataFrame(HC_image_paths[:no_of_images['train_hc']]+\\\n",
    "                                   AD_image_paths[:no_of_images['train_ad']], columns=['image_path'])\n",
    "        trin_img_df_path = os.path.join(save_path, 'train_mri_scan_list.csv')\n",
    "        trin_img_df.to_csv(trin_img_df_path, index=False)\n",
    "\n",
    "        val_img_df = pd.DataFrame(HC_image_paths[no_of_images['train_hc']:(no_of_images['train_hc']+no_of_images['val_hc'])]+\\\n",
    "                                   AD_image_paths[no_of_images['train_ad']:(no_of_images['train_ad']+no_of_images['val_ad'])], columns=['image_path'])\n",
    "        val_img_df_path = os.path.join(save_path, 'val_mri_scan_list.csv')\n",
    "        val_img_df.to_csv(val_img_df_path, index=False)\n",
    "\n",
    "        test_img_df = pd.DataFrame(HC_image_paths[no_of_images['train_hc']+no_of_images['val_hc']:]+\\\n",
    "                                   AD_image_paths[no_of_images['train_ad']+no_of_images['val_ad']:], columns=['image_path'])\n",
    "        test_img_df_path = os.path.join(save_path, 'test_mri_scan_list.csv')\n",
    "        test_img_df.to_csv(test_img_df_path, index=False)\n",
    "\n",
    "        return trin_img_df_path, val_img_df_path, test_img_df_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6b1fee48-13b4-49a8-a96a-12dae6653446",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ADNIAlzheimerDataset(Dataset):\n",
    "    def __init__(self, image_df_paths, transform=None):\n",
    "        self.image_df_paths = image_df_paths\n",
    "        self.transform = transform\n",
    "        self.df = pd.read_csv(self.image_df_paths)\n",
    "        self.desired_width = config['img_size']\n",
    "        self.desired_height = config['img_size']\n",
    "        self.desired_depth = config['depth']\n",
    "\n",
    "    def __label_extract(self, im_path):\n",
    "        if \"_AD_\" in im_path:\n",
    "            return 1\n",
    "        elif \"_HC_\" in im_path:\n",
    "            return 0\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        data = {}\n",
    "        image_filepath = self.df['image_path'][idx]\n",
    "        image = nib.as_closest_canonical(nib.load(image_filepath))\n",
    "        image = image.get_fdata()\n",
    "        xdim, ydim, zdim = image.shape\n",
    "        image = np.pad(image, [((256-xdim)//2, (256-xdim)//2), ((256-ydim)//2, (256-ydim)//2), ((256-zdim)//2, (256-zdim)//2)], 'constant', constant_values=0)\n",
    "        #image = image.reshape(image.shape[2], image.shape[1], image.shape[0])\n",
    "\n",
    "        width_factor = self.desired_width / image.shape[0]\n",
    "        height_factor = self.desired_height / image.shape[1]\n",
    "        depth_factor = self.desired_depth / image.shape[-1]\n",
    "\n",
    "        image = zoom(image, (width_factor, height_factor, depth_factor), order=1)\n",
    "        image = image.reshape(1, image.shape[0], image.shape[1], image.shape[2])\n",
    "        image = image.astype('float32')\n",
    "        image = torch.from_numpy(image)\n",
    "        \n",
    "        label = self.__label_extract(image_filepath)\n",
    "        \n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "245e2385",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_ad': 325, 'val_ad': 69, 'test_ad': 71, 'train_hc': 170, 'val_hc': 36, 'test_hc': 37}\n",
      "Total number of train, validation and test images are 495, 105 and 108 respectively.\n"
     ]
    }
   ],
   "source": [
    "data_paths = DataPaths()\n",
    "paths = data_paths.mri_path_loading()\n",
    "trin_img_df_path, val_img_df_path, test_img_df_path = data_paths.train_val_test_division()\n",
    "\n",
    "train_dataset = ADNIAlzheimerDataset(trin_img_df_path)\n",
    "val_dataset = ADNIAlzheimerDataset(val_img_df_path)\n",
    "test_dataset = ADNIAlzheimerDataset(test_img_df_path)\n",
    "\n",
    "def saveTensors(dataset, data_type):\n",
    "    path = '/home/admin1/Arindam/Alzheimer/ViT/data/MIRIAD/MRIs'\n",
    "    data_path = os.path.join(path, data_type)\n",
    "    if os.path.exists(data_path)==False:\n",
    "        os.mkdir(data_path)\n",
    "    \n",
    "    labels = {\n",
    "        0 : 'HC',\n",
    "        1 : 'AD'\n",
    "    }\n",
    "    \n",
    "    for label in labels.keys():\n",
    "        os.mkdir(os.path.join(data_path, labels[label]))\n",
    "    \n",
    "    print(f\"Processing for {data_type} data is starting. Data will be saved at {data_path}\")\n",
    "    print(f\"Total number of images are: {len(dataset)}\")\n",
    "    \n",
    "    start = time.time()\n",
    "    for idx in range(len(dataset)):\n",
    "        tensor, label = dataset.__getitem__(idx)\n",
    "        tensor_path = f\"{data_path}/{labels[label]}/{idx}.pt\"\n",
    "        torch.save(tensor, tensor_path)\n",
    "        \n",
    "        if (idx+1)%100==0:\n",
    "            print(f\"{idx+1} images done.\")\n",
    "    \n",
    "    req_time = time.time() - start\n",
    "    print(f\"Total time required for processing the data is {req_time// 60} minutes {req_time%60} sec.\")\n",
    "    print(f\"Processing of a single image took {req_time/(1.0*len(dataset))} sec.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "63fda111",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing for Test data is starting. Data will be saved at /home/admin1/Arindam/Alzheimer/ViT/data/MIRIAD/MRIs/Test\n",
      "Total number of images are: 108\n",
      "100 images done.\n",
      "Total time required for processing the data is 0.0 minutes 36.04144597053528 sec.\n",
      "Processing of a single image took 0.3337170923197711 sec.\n"
     ]
    }
   ],
   "source": [
    "saveTensors(test_dataset, 'Test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5d1f73c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing for Val data is starting. Data will be saved at /home/admin1/Arindam/Alzheimer/ViT/data/MIRIAD/MRIs/Val\n",
      "Total number of images are: 105\n",
      "100 images done.\n",
      "Total time required for processing the data is 0.0 minutes 35.26710748672485 sec.\n",
      "Processing of a single image took 0.33587721415928434 sec.\n"
     ]
    }
   ],
   "source": [
    "saveTensors(val_dataset, 'Val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f898f8e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing for Train data is starting. Data will be saved at /home/admin1/Arindam/Alzheimer/ViT/data/MIRIAD/MRIs/Train\n",
      "Total number of images are: 495\n",
      "100 images done.\n",
      "200 images done.\n",
      "300 images done.\n",
      "400 images done.\n",
      "Total time required for processing the data is 2.0 minutes 46.547834157943726 sec.\n",
      "Processing of a single image took 0.33646027102614895 sec.\n"
     ]
    }
   ],
   "source": [
    "saveTensors(train_dataset, 'Train')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
